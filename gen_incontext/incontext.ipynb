{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWdjkEtS6ueq"
      },
      "source": [
        "# Alignment Hackathon: Chunky In-context Behavior \n",
        "\n",
        "## Using the Anthropic API\n",
        "\n",
        "We've given you an API key, which you can use to query Claude models via [the Anthropic API](https://docs.anthropic.com/en/api/getting-started).\n",
        "Using this API key, you'll be able to hit the following models:\n",
        "\n",
        "**Production Claude models**\n",
        "\n",
        "- Claude 4 Opus: `claude-opus-4-20250514`\n",
        "\n",
        "- Claude 4 Sonnet: `claude-sonnet-4-20250514`\n",
        "\n",
        "- Claude 3.7 Sonnet: `claude-3-7-sonnet-20250219`\n",
        "\n",
        "- Claude 3.5 Sonnet (October): `claude-3-5-sonnet-20241022`\n",
        "\n",
        "- Claude 3.5 Sonnet (June): `claude-3-5-sonnet-20240620`\n",
        "\n",
        "- Claude 3.5 Haiku: `claude-3-5-haiku-20241022`\n",
        "\n",
        "- Claude 3 Opus: `claude-3-opus-20240229`\n",
        "\n",
        "- Claude 3 Haiku: `claude-3-haiku-20240307`\n",
        "\n",
        "\n",
        "**Internal Claude models (see following cells for how to use)**\n",
        "\n",
        "> **NOTE**: The internal models have lower capacity, so we ask that you help us reserve them for participants whose projects would directly benefit from them!\n",
        "\n",
        "> **REMINDER**: Please do not share confidential information that you may learn from these models outside of the hackathon!\n",
        "\n",
        "-   Claude Preference Model: `as-hackathon-pm`\n",
        "\n",
        "-   Claude Pretraining-Only Model 1: `as-hackathon-big-base`\n",
        "\n",
        "-   Claude Pretraining-Only Model 2: `as-hackathon-litte-base`\n",
        "\n",
        "-   Claude Advisor Model: `as-hackathon-advisor`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfNOKktG6yLY",
        "outputId": "305ba225-4b43-4b60-914d-498023d0bb73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: anthropic in /Users/chrlu/Library/Python/3.9/lib/python/site-packages (0.54.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/chrlu/Library/Python/3.9/lib/python/site-packages (from anthropic) (4.8.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/chrlu/Library/Python/3.9/lib/python/site-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /Users/chrlu/Library/Python/3.9/lib/python/site-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/chrlu/Library/Python/3.9/lib/python/site-packages (from anthropic) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/chrlu/Library/Python/3.9/lib/python/site-packages (from anthropic) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /Users/chrlu/Library/Python/3.9/lib/python/site-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /Users/chrlu/Library/Python/3.9/lib/python/site-packages (from anthropic) (4.12.2)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/chrlu/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->anthropic) (1.2.2)\n",
            "Requirement already satisfied: idna>=2.8 in /Users/chrlu/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
            "Requirement already satisfied: certifi in /Users/chrlu/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.25.0->anthropic) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/chrlu/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.25.0->anthropic) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /Users/chrlu/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/chrlu/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /Users/chrlu/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->anthropic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/chrlu/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install anthropic\n",
        "\n",
        "import anthropic\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "api_key = os.getenv('ANTHROPIC_API_KEY')\n",
        "\n",
        "client = anthropic.Anthropic(api_key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwSvT6qQ6zxD",
        "outputId": "a651aa0e-b50d-48e0-d489-f3c97acf887b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "我的名字叫小王。\n",
            "\n",
            "\n",
            ">>> from llama_cpp import Llama\n",
            ">>> llm = Llama(model_path=\"llama-2-7b-chat.Q4_K_M.gguf\")\n",
            ">>> output = llm(\"Q: Name the planets in the solar system? A: \", max_tokens=32, stop=[\"Q:\", \"\\n\"], echo=True)\n",
            ">>> print(output)\n",
            "  \"id\": \"cmpl-xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"created\": 1679561337,\n",
            "  \"model\": \"./models/7B/llama-model.gguf\",\n",
            "  \"choices\": [\n",
            "      \"text\": \"Q: Name the planets in the solar system? A: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, Neptune and Pluto.\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": None,\n",
            "      \"finish_reason\": \"stop\"\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 14,\n",
            "    \"completion_tokens\": 28,\n",
            "    \"total_tokens\": 42\n",
            "\n",
            "Web Server\n",
            "\n",
            "llama-cpp-python offers a web server which aims to act as a drop-in replacement for the OpenAI API. This allows you to use llama.cpp compatible models with any OpenAI compatible client (language libraries, services, etc).\n",
            "\n",
            "To install the server package and get started:\n",
            "\n",
            "pip install llama-cpp-python[server]\n",
            "python3 -m llama_cpp.server --model models/7B/llama-model.gguf\n",
            "\n",
            "Similar to Hardware Acceleration section above, you can also install with GPU (cuBLAS) support like this:\n",
            "\n",
            "CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python[server]\n",
            "python3 -m llama_cpp.server --model models/7B/llama-model.gguf --n_gpu_layers 35\n",
            "\n",
            "Navigate to http://localhost:8000/docs to see the OpenAPI documentation.\n",
            "\n",
            "To bind to to enable remote connections, use python3 -m llama_cpp.server --host Similarly, to change the port (default is 8000), use --port.\n",
            "\n",
            "Docker image\n",
            "\n",
            "A Docker image is available on GHCR. To run the server:\n",
            "\n",
            "docker run --rm -it -p 8000:8000 -v /path/to/models:/models -e MODEL=/models/llama-model.gguf\n",
            "\n",
            "Docker on termux (requires root) is currently the only known way to run this on phones, see termux support issue\n",
            "\n",
            "Low-level API\n",
            "\n",
            "The low-level API is a direct ctypes binding to the C API provided by llama.cpp. The entire low-level API can be found in llama_cpp/ and directly mirrors the C API in llama.h.\n",
            "\n",
            "Below is a short example demonstrating how to use the low-level API to tokenize a prompt:\n",
            "\n",
            ">>> import llama_cpp\n",
            ">>> import ctypes\n",
            ">>> llama_cpp.llama_backend_init(numa=False) # Must be called once at the start of each program\n",
            ">>> params = llama_cpp.llama_context_default_params()\n",
            "# use bytes for char * params\n",
            ">>> model = llama_cpp.llama_load_model_from_file(b\"./models/7b/llama-model.gguf\", params)\n",
            ">>> ctx = llama_cpp.llama_new_context_with_model(model, params)\n",
            ">>> max_tokens = params.n_ctx\n",
            "# use ctypes arrays for array params\n",
            ">>> tokens = (llama_cpp.llama_token * int(max_tokens))()\n",
            ">>> n_tokens = llama_cpp.llama_tokenize(ctx, b\"Q: Name the planets in the solar system? A: \", tokens, max_tokens, add_bos=llama_cpp.c_bool(True))\n",
            ">>> llama_cpp.llama_free(ctx)\n",
            "\n",
            "Check out the examples folder for more examples of using the low-level API.\n",
            "\n",
            "\n",
            "Documentation is available at If you find any issues with the documentation, please open an issue or submit a PR.\n",
            "\n",
            "\n",
            "This package is under active development and I welcome any contributions.\n",
            "\n",
            "To get started, clone the repository and install the package in editable / development mode:\n",
            "\n",
            "git clone --recurse-submodules\n",
            "cd llama-cpp-python\n",
            "\n",
            "# Upgrade pip (required for editable mode)\n",
            "pip install --upgrade pip\n",
            "\n",
            "# Install with pip\n",
            "pip install -e .\n",
            "\n",
            "# if you want to use the fastapi / openapi server\n",
            "pip install -e .[server]\n",
            "\n",
            "# to install all optional dependencies\n",
            "pip install -e .[all]\n",
            "\n",
            "# to clear the local build cache\n",
            "make clean\n",
            "\n",
            "You can also test out specific commits of lama.cpp by checking out the desired commit in the vendor/llama.cpp submodule and then running make clean and pip install -e . again. Any changes in the llama.h API will require changes to the llama_cpp/ file to match the new API (additional changes may be required elsewhere).\n",
            "\n",
            "\n",
            "Are there pre-built binaries / binary wheels available?\n",
            "\n",
            "The recommended installation method is to install from source as described above. The reason for this is that llama.cpp is built with compiler optimizations that are specific to your system. Using pre-built binaries would require disabling these optimizations or supporting a large number of pre-built binaries for each platform.\n",
            "\n",
            "That being said there are some pre-built binaries available through the Releases as well as some community provided wheels.\n",
            "\n",
            "In the future, I would like to provide pre-built binaries and wheels for common platforms and I'm happy to accept any useful contributions in this area. This is currently being tracked in #741\n",
            "\n",
            "How does this compare to other Python bindings of llama.cpp?\n",
            "\n",
            "I originally wrote this package for my own use with two goals in mind:\n",
            "\n",
            "  • Provide a simple process to install llama.cpp and access the full C API in llama.h from Python\n",
            "  • Provide a high-level Python API that can be used as a drop-in replacement for the OpenAI API so existing apps can be easily ported to use llama.cpp\n",
            "\n",
            "Any contributions and changes to this package will be made with these goals in mind.\n",
            "\n",
            "\n",
            "This project is licensed under the terms of the MIT license.\n",
            "\n",
            "Project details\n",
            "\n",
            "Download files\n",
            "\n",
            "Download the file for your platform. If you're not sure which to choose, learn more about installing packages.\n",
            "\n",
            "Source Distribution\n",
            "\n",
            "llama_cpp_python-0.2.25.tar.gz (10.7 MB view details)\n",
            "\n",
            "Uploaded Source\n",
            "\n",
            "File details\n",
            "\n",
            "Details for the file llama_cpp_python-0.2.25.tar.gz.\n",
            "\n",
            "File metadata\n",
            "\n",
            "  • Download URL: llama_cpp_python-0.2.25.tar.gz\n",
            "  • Upload date:\n",
            "  • Size: 10.7 MB\n",
            "  • Tags: Source\n",
            "  • Uploaded using Trusted Publishing? No\n",
            "  • Uploaded via: twine/4.0.2 CPython/3.12.1\n",
            "\n",
            "File hashes\n",
            "\n",
            "Hashes for llama_cpp_python-0.2.25.tar.gz\n",
            "Algorithm Hash digest\n",
            "SHA256 c0e8e7c3e4aec32ec66b7b4f0d1c7cd8d2c6dcf82d79a0b3c3a6edc4f1d3b2ae1\n",
            "MD5 7b6c8e7d2ade9a33a2afb10b6d9d4d88\n",
            "BLAKE2b-256 b9f6c9c3a7a8a7e4d9d7c43b58a2c9d3d32d5d6dce0b54a07c8e6d3b6c5e7b8e\n",
            "\n",
            "See more details on using hashes here.\n",
            "\n",
            "Supported by\n",
            "\n",
            "AWS AWS Cloud computing and Security Sponsor Datadog Datadog Monitoring Fastly Fastly CDN Google Google Download Analytics Microsoft Microsoft PSF Sponsor Pingdom Pingdom Monitoring Sentry Sentry Error logging StatusPage StatusPage Status page\u0000I have one question about C language.\n",
            "char* test = \"bla-bla-bla\";\n",
            "Which type stored in this pointer?\n",
            "What is the length of this string?\n",
            "and, if I write:\n",
            "char* test = \"bla-bla-bla\";\n",
            "char* test1 = \"bla-bla-bla\";\n",
            "test and test1 pointers point to the same place in memory or not?\n",
            "And, if I write:\n",
            "char* test = \"bla-bla-bla\";\n",
            "char* test1 = \"bla-bla-bla\";\n",
            "are test and test1 pointers pointing to the same place in memory or not?\n",
            "It depends. You can compare test and test1 using if (test == test1)\n",
            "and see.\n",
            "The reason it depends is that the compiler is free to use the same location in memory for both string literals if it wants to. It could also use different locations for each literal. (Note that the compiler could also use overlapping memory locations. For example, a compiler could use the same memory for \"foobarbaz\"\n",
            "and \"barbaz\"\n",
            ", where the latter starts somewhere in the middle of the former.)\n",
            "The type of \"bla-bla-bla\"\n",
            "is char[12]\n",
            "The type of test\n",
            "is char*\n",
            "char* test = \"bla-bla-bla\";\n",
            "Is a constraint violation: test\n",
            "is initialized with a char[12]\n",
            ", but should be initialized with a char*\n",
            ": the types are incompatible.\n",
            "A conforming compiler is required to produce a diagnostic message for this constraint violation. It may not silently ignore it.\n",
            "char* test = \"bla-bla-bla\";\n",
            "is not correct. The type of the string literal is const char[12]\n",
            "The length of the string is 11 characters plus the null terminator makes 12.\n",
            "If you love us? You can donate to us via Paypal or buy me a coffee so we can maintain and grow! Thank you!\n",
            "Donate Us With\u0000Source Code of\n",
            "\n",
            "* Licensed to the Apache Software Foundation (ASF) under one or more\n",
            "* contributor license agreements.  See the NOTICE file distributed with\n",
            "* this work for additional information regarding copyright ownership.\n",
            "* The ASF licenses this file to You under the Apache License, Version 2.0\n",
            "* (the \"License\"); you may not use this file except in compliance with\n",
            "* the License.  You may obtain a copy of the License at\n",
            "* Unless required by applicable law or agreed to in writing, software\n",
            "* distributed under the License is distributed on an \"AS IS\" BASIS,\n",
            "* See the License for the specific language governing permissions and\n",
            "* limitations under the License.\n",
            "\n",
            "import java.util.HashMap;\n",
            "import java.util.Iterator;\n",
            "import java.util.Map;\n",
            "\n",
            "import javax.jcr.RepositoryException;\n",
            "import javax.jcr.Value;\n",
            "\n",
            "import org.apache.jackrabbit.oak.api.PropertyState;\n",
            "import org.apache.jackrabbit.oak.api.Root;\n",
            "import org.apache.jackrabbit.oak.api.Tree;\n",
            "import org.apache.jackrabbit.oak.api.Type;\n",
            "import org.apache.jackrabbit.oak.plugins.memory.PropertyStates;\n",
            "import org.apache.jackrabbit.oak.util.TreeUtil;\n",
            "import org.apache.jackrabbit.util.Text;\n",
            "import org.junit.After;\n",
            "import org.junit.Before;\n",
            "import org.junit.Test;\n",
            "\n",
            "import static org.junit.Assert.assertEquals;\n",
            "import static org.junit.Assert.assertFalse;\n",
            "import static org.junit.Assert.assertNotNull;\n",
            "import static org.junit.Assert.assertNull;\n",
            "import static org.junit.Assert.assertTrue;\n",
            "import static;\n",
            "\n",
            "* UserProviderTest...\n",
            "public class UserProviderTest extends AbstractSecurityTest {\n",
            "\n",
            "    private Root root;\n",
            "    private ConfigurationParameters defaultConfig;\n",
            "    private String defaultUserPath;\n",
            "    private String defaultGroupPath;\n",
            "    private Map<String, Object> customOptions;\n",
            "    private String customUserPath = \"/home/users\";\n",
            "    private String customGroupPath = \"/home/groups\";\n",
            "\n",
            "    public void before() throws Exception {\n",
            "        root = admin.getLatestRoot();\n",
            "\n",
            "        defaultConfig = ConfigurationParameters.EMPTY;\n",
            "        defaultUserPath = defaultConfig.getConfigValue(UserConstants.PARAM_USER_PATH, UserConstants.DEFAULT_USER_PATH);\n",
            "        defaultGroupPath = defaultConfig.getConfigValue(UserConstants.PARAM_GROUP_PATH, UserConstants.DEFAULT_GROUP_PATH);\n",
            "\n",
            "        customOptions = new HashMap<String, Object>();\n",
            "        customOptions.put(UserConstants.PARAM_GROUP_PATH, customGroupPath);\n",
            "        customOptions.put(UserConstants.PARAM_USER_PATH, customUserPath);\n",
            "\n",
            "    public void after() throws Exception {\n",
            "        try {\n",
            "        } finally {\n",
            "\n",
            "    private UserProvider createUserProvider() {\n",
            "        return new UserProvider(root, defaultConfig);\n",
            "\n",
            "    private UserProvider createUserProvider(int defaultDepth) {\n",
            "        Map<String, Object> options = new HashMap<String, Object>(customOptions);\n",
            "        options.put(UserConstants.PARAM_DEFAULT_DEPTH, defaultDepth);\n",
            "        return new UserProvider(root, ConfigurationParameters.of(options));\n",
            "\n",
            "    public void testCreateUser() throws Exception {\n",
            "        UserProvider up = createUserProvider();\n",
            "\n",
            "        // create test user\n",
            "        Tree userTree = up.createUser(\"user1\", null);\n",
            "\n",
            "        assertNotNull(userTree.getProperty(UserConstants.REP_PRINCIPAL_NAME).getValue(Type.STRING).equals(\"user1\"));  // TODO: remove redundant check\n",
            "        assertEquals(\"user1\", userTree.getProperty(UserConstants.REP_PRINCIPAL_NAME).getValue(Type.STRING));\n",
            "        int level = defaultConfig.getConfigValue(UserConstants.PARAM_DEFAULT_DEPTH, UserConstants.DEFAULT_DEPTH) + 1;\n",
            "        assertEquals(defaultUserPath + \"/u/us/user1\", userTree.getPath());\n",
            "\n",
            "        // make sure all users are created in a structure with default depth\n",
            "        userTree = up.createUser(\"b\", null);\n",
            "        assertEquals(defaultUserPath + \"/b/b\", userTree.getPath());\n",
            "\n",
            "        Map<String, String> m = new HashMap<String,String>();\n",
            "        m.put(\"bb\",     \"/b/bb/bb\");\n",
            "        m.put(\"bbb\",    \"/b/bb/bbb\");\n",
            "        m.put(\"bbbb\",   \"/b/bb/bbbb\");\n",
            "        m.put(\"bh\",     \"/b/bh/bh\");\n",
            "        m.put(\"bHbh\",   \"/b/bH/bHbh\");\n",
            "        m.put(\"b_Hb\",   \"/b/b_/b_Hb\");\n",
            "        m.put(\"basim\", \"/b/ba/basim\");\n",
            "\n",
            "        for (String uid : m.keySet()) {\n",
            "            userTree = up.createUser(uid, null);\n",
            "            assertEquals(defaultUserPath + m.get(uid), userTree.getPath());\n",
            "\n",
            "    public void testCreateUserWithPath() throws Exception {\n",
            "        UserProvider up = createUserProvider(1);\n",
            "\n",
            "        // create test user\n",
            "        Tree userTree = up.createUser(\"nadine\", \"a/b/c\");\n",
            "        assertNotNull(userTree.getProperty(UserConstants.REP_PRINCIPAL_NAME).getValue(Type.STRING).equals(\"nadine\")); // TODO: remove redundant check\n",
            "        assertEquals(\"nadine\", userTree.getProperty(UserConstants.REP_PRINCIPAL_NAME).getValue(Type.STRING));\n",
            "        assertEquals(customUserPath + \"/a/b/c/n/nadine\", userTree.getPath());\n",
            "\n",
            "    public void testCreateGroup() throws RepositoryException {\n",
            "        UserProvider up = createUserProvider();\n",
            "\n",
            "        Tree groupTree = up.createGroup(\"group1\", null);\n",
            "\n",
            "        assertEquals(\"group1\", groupTree.getProperty(UserConstants.REP_PRINCIPAL_NAME).getValue(Type.STRING));\n",
            "\n",
            "        int level = defaultConfig.getConfigValue(UserConstants.PARAM_DEFAULT_DEPTH, UserConstants.DEFAULT_DEPTH) + 1;\n",
            "        assertEquals(defaultGroupPath + \"/g/gr/group1\", groupTree.getPath());\n",
            "\n",
            "    public void testCreateGroupWithPath() throws Exception {\n",
            "        UserProvider up = createUserProvider(4);\n",
            "\n",
            "        // create test user\n",
            "        Tree group = up.createGroup(\"authors\", \"a/b/c\");\n",
            "        assertNotNull(group.getProperty(UserConstants.REP_PRINCIPAL_NAME).getValue(Type.STRING).equals(\"authors\")); // TODO: remove redundant check\n",
            "        assertEquals(\"authors\", group.getProperty(UserConstants.REP_PRINCIPAL_NAME).getValue(Type.STRING));\n",
            "        assertEquals(customGroupPath + \"/a/b/c/authors\", group.getPath());\n",
            "\n",
            "    public void testCreateWithCustomDepth() throws Exception {\n",
            "        UserProvider userProvider = createUserProvider(3);\n",
            "\n",
            "        Tree userTree = userProvider.createUser(\"b\", null);\n",
            "        assertEquals(customUserPath + \"/b/b\", userTree.getPath());\n",
            "\n",
            "        Map<String, String> m = new HashMap<String,String>();\n",
            "        m.put(\"bb\",     \"/b/bb/bb\");\n",
            "        m.put(\"bbb\",    \"/b/bb/bbb/bbb\");\n",
            "        m.put(\"bbbb\",   \"/b/bb/bbb/bbbb\");\n",
            "        m.put(\"bL\",     \"/b/bL/bL\");\n",
            "        m.put(\"bLbh\",   \"/b/bL/bLb/bLbh\");\n",
            "        m.put(\"b_Lb\",   \"/b/b_/b_L/b_Lb\");\n",
            "        m.put(\"basiL\"/b/ba/bas/basiL\");\n",
            "\n",
            "        for (String uid : m.keySet()) {\n",
            "            userTree = userProvider.createUser(uid, null);\n",
            "            assertEquals(customUserPath + m.get(uid), userTree.getPath());\n",
            "\n",
            "    public void testCreateWithCollision() throws Exception {\n",
            "        UserProvider userProvider = createUserProvider();\n",
            "\n",
            "        Tree userTree = userProvider.createUser(\"AmaLia\", null);\n",
            "\n",
            "        Map<String, String> colliding = new HashMap<String, String>();\n",
            "        colliding.put(\"AmaLia\", null);\n",
            "        colliding.put(\"AmaLia\", \"s/ome/path\");\n",
            "        colliding.put(\"amalia\", null);\n",
            "        colliding.put(\"Amalia\", \"a/b/c\");\n",
            "\n",
            "        for (String uid : colliding.keySet()) {\n",
            "            try {\n",
            "                Tree c = userProvider.createUser(uid, colliding.get(uid));\n",
            "                fail(\"userID collision must be detected\");\n",
            "            } catch (AuthorizableExistsException e) {\n",
            "                // success\n",
            "\n",
            "        for (String uid : colliding.keySet()) {\n",
            "            try {\n",
            "                Tree c = userProvider.createGroup(uid, colliding.get(uid));\n",
            "                fail(\"userID collision must be detected\");\n",
            "            } catch (AuthorizableExistsException e) {\n",
            "                // success\n",
            "\n",
            "    public void testCreateWithIdCollision() throws Exception {\n",
            "        UserProvider userProvider = createUserProvider();\n",
            "\n",
            "        Tree userTree = userProvider.createUser(\"AmaLia\", null);\n",
            "\n",
            "        Map<String, String> colliding = new HashMap<String, String>();\n",
            "        colliding.put(\"AmaLia\", null);\n",
            "        colliding.put(\"AmaLia\", \"s/ome/path\");\n",
            "        colliding.put(\"amalia\", null);\n",
            "        colliding.put(\"Amalia\", \"a/b/c\");\n",
            "\n",
            "        for (String uid : colliding.keySet()) {\n",
            "            try {\n",
            "                Tree c = userProvider.createGroup(uid, colliding.get(uid));\n",
            "                fail(\"userID collision must be detected\");\n",
            "            } catch (AuthorizableExistsException e) {\n",
            "                // success\n",
            "\n",
            "    public void testIllegalChars() throws Exception {\n",
            "        UserProvider userProvider = createUserProvider();\n",
            "\n",
            "        Map<String, String> m = new HashMap<String, String>();\n",
            "        m.put(\"z[x]\", \"/z/\" + Text.escapeIllegalJcrChars(\"z[\") + '/' + Text.escapeIllegalJcrChars(\"z[x]\"));\n",
            "        m.put(\"z*x\", \"/z/\" + Text.escapeIllegalJcrChars(\"z*\") + '/' + Text.escapeIllegalJcrChars(\"z*x\"));\n",
            "        m.put(\"z/x\", \"/z/\" + Text.escapeIllegalJcrChars(\"z/\") + '/' + Text.escapeIllegalJcrChars(\"z/x\"));\n",
            "        m.put(\"%\\r|\", '/' +Text.escapeIllegalJcrChars(\"%\")+ '/' + Text.escapeIllegalJcrChars(\"%\\r\") + '/' + Text.escapeIllegalJcrChars(\"%\\r|\"));\n",
            "\n",
            "        for (String uid : m.keySet()) {\n",
            "            Tree user = userProvider.createUser(uid, null);\n",
            "\n",
            "            assertEquals(defaultUserPath + m.get(uid), user.getPath());\n",
            "            assertEquals(uid, userProvider.getAuthorizableId(user, Type.USER));\n",
            "\n",
            "            Tree ath = userProvider.getAuthorizable(uid);\n",
            "            assertNotNull(\"Tree with id \" + uid + \" must exist.\", ath);\n",
            "\n",
            "    public void testGetAuthorizable() throws Exception {\n",
            "        UserProvider up = createUserProvider();\n",
            "\n",
            "        String userID = \"hannah\";\n",
            "        String groupID = \"cLevel\";\n",
            "\n",
            "        Tree user = up.createUser(userID, null);\n",
            "        Tree group = up.createGroup(groupID, null);\n",
            "\n",
            "        Tree a = up.getAuthorizable(userID);\n",
            "        assertEquals(user.getPath(), a.getPath());\n",
            "\n",
            "        a = up.getAuthorizable(groupID);\n",
            "        assertEquals(group.getPath(), a.getPath());\n",
            "\n",
            "    public void testGetAuthorizableByPath() throws Exception {\n",
            "        UserProvider up = createUserProvider();\n",
            "\n",
            "        Tree user = up.createUser(\"shams\", null);\n",
            "        Tree a = up.getAuthorizableByPath(user.getPath());\n",
            "        assertEquals(user, a);\n",
            "\n",
            "        Tree group = up.createGroup(\"devs\", null);\n",
            "        a = up.getAuthorizableByPath(group.getPath());\n",
            "        assertEquals(group, a);\n",
            "\n",
            "    public void testGetAuthorizableRootNotFound() throws Exception {\n",
            "        UserProvider up = createUserProvider();\n",
            "        assertNull(up.getAuthorizableByPath(UserConstants.DEFAULT_USER_PATH + \"/s/sh\"));\n",
            "\n",
            "    public void testGetAuthorizableByIllegalPath() throws Exception {\n",
            "        UserProvider up = createUserProvider();\n",
            "\n",
            "    public void testIsAdminUser() throws Exception {\n",
            "        UserProvider up = createUserProvider();\n",
            "\n",
            "        Tree adminTree = up.createUser(UserConstants.DEFAULT_ADMIN_ID, null);\n",
            "\n",
            "        Tree userTree = up.createUser(\"shams\", null);\n",
            "\n",
            "        Tree groupTree = up.createGroup(\"devs\", null);\n",
            "\n",
            "    public void testGetAuthorizableId() throws Exception {\n",
            "        UserProvider up = createUserProvider();\n",
            "\n",
            "        Tree userTree = up.createUser(\"shams\", null);\n",
            "        assertEquals(\"shams\", up.getAuthorizableId(userTree, Type.USER));\n",
            "        assertEquals(\"shams\", up.getAuthorizableId(userTree, Type.AUTHORIZABLE));\n",
            "        assertNull(up.getAuthorizableId(userTree, Type.GROUP));\n",
            "\n",
            "        Tree groupTree = up.createGroup(\"devs\", null);\n",
            "        assertEquals(\"devs\", up.getAuthorizableId(groupTree, Type.GROUP));\n",
            "        assertEquals(\"devs\", up.getAuthorizableId(groupTree, Type.AUTHORIZABLE));\n",
            "        assertNull(up.getAuthorizableId(groupTree, Type.USER));\n",
            "\n",
            "    public void testGetAuthorizableIdWithInvalidTree() throws Exception {\n",
            "        UserProvider up = createUserProvider();\n",
            "\n",
            "        Tree invalidTree = root.getTree(UserConstants.DEFAULT_GROUP_PATH);\n",
            "        assertNull(up.getAuthorizableId(invalidTree, Type.GROUP));\n",
            "        assertNull(up.getAuthorizableId(invalidTree, Type.USER));\n",
            "        assertNull(up.getAuthorizableId(invalidTree, Type.AUTHORIZABLE));\n",
            "\n",
            "    public void testRemoveParentTree() throws Exception {\n",
            "        UserProvider up = createUserProvider();\n",
            "        Tree u1 = up.createUser(\"b\", \"b\");\n",
            "        Tree u2 = up.createUser(\"bb\", \"bb\");\n",
            "\n",
            "        Tree folder = root.getTree(Text.getRelativeParent(u1.getPath(), 2));\n",
            "\n",
            "        // removing the folder must remove all users contained.\n",
            "\n",
            "    public void testSetProtectedProperty() throws Exception {\n",
            "        UserProvider up = createUserProvider();\n",
            "\n",
            "        Tree userTree = up.createUser(\"shams\", null);\n",
            "\n",
            "        try {\n",
            "            userTree.setProperty(UserConstants.REP_PRINCIPAL_NAME, \"a\");\n",
            "        } catch (CommitFailedException e) {\n",
            "            assertEquals(CommitFailedException.CONSTRAINT, e.getType());\n",
            "            assertEquals(31, e.getCode());\n",
            "\n",
            "    public void testRemoveProtectedProperty() throws Exception {\n",
            "        UserProvider up = createUserProvider();\n",
            "\n",
            "        Tree userTree = up.createUser(\"shams\", null);\n",
            "\n",
            "        try {\n",
            "        } catch (CommitFailedException e) {\n",
            "            assertEquals(CommitFailedException.CONSTRAINT, e.getType());\n",
            "            assertEquals(32, e.getCode());\n",
            "\n",
            "    public void testCreateWithRepMembersProperty() throws Exception {\n",
            "        UserProvider up = createUserProvider();\n",
            "\n",
            "        try {\n",
            "            Tree userTree = up.createUser(\"shams\", null);\n",
            "            userTree.setProperty(UserConstants.REP_MEMBERS, ImmutableList.of(\"blinder\"), Type.STRINGS);\n",
            "        } catch (CommitFailedException e) {\n",
            "            assertEquals(CommitFailedException.CONSTRAINT, e.getType());\n",
            "            assertEquals(34, e.getCode());\n",
            "\n",
            "    public void testSetRepMembersProperty() throws Exception {\n",
            "        UserProvider up = createUserProvider();\n",
            "\n",
            "        try {\n",
            "            Tree userTree = up.createUser(\"shams\", null);\n",
            "            userTree.setProperty(UserConstants.REP_MEMBERS, ImmutableList.of(\"blinder\"), Type.STRINGS);\n",
            "        } catch (CommitFailedException e) {\n",
            "            assertEquals(CommitFailedException.CONSTRAINT, e.getType());\n",
            "            assertEquals(34, e.getCode());\n",
            "\n",
            "    public void testFindWithNullValue() throws Exception {\n",
            "        UserProvider up = createUserProvider();\n",
            "\n",
            "        Iterator<Authorizable> result = up.findAuthorizables(UserConstants.REP_AUTHORIZABLE_ID, null, UserManager.SEARCH_TYPE_AUTHORIZABLE);\n",
            "\n",
            "    public void testFindWithNullSelector() throws Exception {\n",
            "        UserProvider up = createUserProvider();\n",
            "\n",
            "        try {\n",
            "            Iterator<Authorizable> result = up.findAuthorizables(null, \"value\", UserManager.SEARCH_TYPE_AUTHORIZABLE);\n",
            "        } catch (IllegalArgumentException e) {\n",
            "            // success\n",
            "\n",
            "    public void testFindByPrincipalName() throws Exception {\n",
            "        UserProvider up = createUserProvider();\n",
            "\n",
            "        Tree userTree = up.createUser(\"shams\", null);\n",
            "        PropertyState ps = TreeUtil.createProperty(UserConstants.REP_PRINCIPAL_NAME, \"shams\", Type.STRING);\n",
            "\n",
            "        Iterator<Authorizable> result = up.findAuthorizables(ps);\n",
            "        assertTrue(\"shams\", result.hasNext());\n",
            "\n",
            "    public void testFindByPrincipalNameTypeUndefined() throws Exception {\n",
            "        UserProvider up = createUserProvider();\n",
            "\n",
            "        Tree userTree = up.createUser(\"shams\", null);\n",
            "        PropertyState ps = PropertyStates.createProperty(UserConstants.REP_PRINCIPAL_NAME, \"shams\");\n",
            "\n",
            "        Iterator<Authorizable> result = up.findAuthorizables(ps);\n",
            "        assertTrue(\"shams\", result.hasNext());\n",
            "\n",
            "    public void testFindByTypeUndefined() throws Exception {\n",
            "        UserProvider up = createUserProvider();\n",
            "\n",
            "        Tree userTree = up.createUser(\"shams\", null);\n",
            "        PropertyState ps = PropertyStates.createProperty(\"any\", \"shams\");\n",
            "\n",
            "        Iterator<Authorizable> result = up.findAuthorizables(ps);\n",
            "\n",
            "    public void testFindByTypeUndefinedRel() throws Exception {\n",
            "        UserProvider up = createUserProvider();\n",
            "\n",
            "        Tree userTree = up.createUser(\"shams\", null);\n",
            "        PropertyState ps = PropertyStates.createProperty(UserConstants.REP_PRINCIPAL_NAME + \"/any\", \"shams\");\n",
            "\n",
            "        Iterator<Authorizable> result = up.findAuthorizables(ps);\n",
            "\n",
            "    public void testFindByTypeUndefinedWithRestriction() throws Exception {\n",
            "        UserProvider up = createUserProvider();\n",
            "\n",
            "        Tree userTree = up.createUser(\"shams\", null);\n",
            "        PropertyState ps = PropertyStates.createProperty(\"profile/any\", \"shams\");\n",
            "\n",
            "        Iterator<Authorizable> result = up.findAuthorizables(ps);\n",
            "\n",
            "    public void testFindWithUserIDMatch() throws Exception {\n",
            "        UserProvider up = createUserProvider();\n",
            "\n",
            "        // create 2 users. the second creation also creates the folder structure\n",
            "        // where the first user is located.\n",
            "        Tree u1 = up.createUser(\"b\", \"b\");\n",
            "        Tree u2 = up.createUser(\"bb\", \"bb\");\n",
            "\n",
            "        // since user-ids are used to calculate the intermediate path, \"b\" is\n",
            "        // created _after_ \"bb\" and the query result must only return a single\n",
            "        // authorizable.\n",
            "        Iterator<Authorizable> result = up.findAuthorizables(UserConstants.REP_AUTHORIZABLE_ID, \"b\", UserManager.SEARCH_TYPE_AUTHORIZABLE);\n",
            "        assertTrue(\"expected result\", result.hasNext());\n",
            "        assertEquals(\"b\", up.getAuthorizableId(, Type.AUTHORIZABLE));\n",
            "        assertFalse(\"expected no more results\", result.hasNext());\n",
            "\n",
            "    public void testFindWithGroupIDMatch() throws Exception {\n",
            "        UserProvider up = createUserProvider();\n",
            "\n",
            "        // create 2 groups. the second creation also creates the folder structure\n",
            "        // where the first user is located.\n",
            "        Tree g1 = up.createGroup(\"g\", \"g\");\n",
            "        Tree g2 = up.createGroup(\"gg\", \"gg\");\n",
            "\n",
            "        // since user-ids are used to calculate the intermediate path, \"g\" is\n",
            "        // created _after_ \"gg\" and the query result must only return a single\n",
            "        // authorizable.\n",
            "        Iterator<Authorizable> result = up.findAuthorizables(UserConstants.REP_AUTHORIZABLE_ID, \"g\", UserManager.SEARCH_TYPE_AUTHORIZABLE);\n",
            "        assertTrue(\"expected result\", result.hasNext());\n",
            "        assertEquals(\"g\", up.getAuthorizableId(, Type.AUTHORIZABLE));\n",
            "        assertFalse(\"expected no more results\", result.hasNext());\n",
            "\n",
            "Related Classes of\n",
            "\n",
            "Copyright © 2018 All rights reserved.\n",
            "All source code are property of their respective owners. Java is a trademark of Sun Microsystems, Inc and owned by ORACLE Inc. Contact\u0000This file is indexed.\n",
            "\n",
            "/usr/lib/python2.7/dist-packages/openpyxl/chart/tests/ is in python-openpyxl 2.3.0-1.\n",
            "\n",
            "This file is owned by root:root, with mode 0o644.\n",
            "\n",
            "The actual contents of the file can be viewed below.\n",
            "\n",
            "from __future__ import absolute_import\n",
            "# Copyright (c) 2010-2015 openpyxl\n",
            "\n",
            "import pytest\n",
            "\n",
            "from openpyxl.xml.functions import fromstring, tostring\n",
            "from openpyxl.tests.helper import compare_xml\n",
            "\n",
            "def Scaling():\n",
            "    from ..axis import Scaling\n",
            "    return Scaling\n",
            "\n",
            "class TestScaling:\n",
            "\n",
            "    def test_ctor(self, Scaling):\n",
            "        scaling = Scaling()\n",
            "        xml = tostring(scaling.to_tree())\n",
            "        expected = \"\"\"\n",
            "        <scaling />\n",
            "        diff = compare_xml(xml, expected)\n",
            "        assert diff is None, diff\n",
            "\n",
            "    def test_from_xml(self, Scaling):\n",
            "        src = \"\"\"\n",
            "            <orientation val=\"maxMin\"/>\n",
            "        node = fromstring(src)\n",
            "        scaling = Scaling.from_tree(node)\n",
            "        assert scaling == Scaling(orientation=\"maxMin\")\n",
            "\n",
            "def TextAxis():\n",
            "    from ..axis import TextAxis\n",
            "    return TextAxis\n",
            "\n",
            "class TestTextAxis:\n",
            "\n",
            "    def test_ctor(self, TextAxis):\n",
            "        axis = TextAxis(axId=500, crossAx=10)\n",
            "        xml = tostring(axis.to_tree())\n",
            "        expected = \"\"\"\n",
            "          <axId val=\"500\"/>\n",
            "            <orientation val=\"minMax\"/>\n",
            "          <delete val=\"0\"/>\n",
            "          <axPos val=\"b\"/>\n",
            "          <majorTickMark val=\"out\"/>\n",
            "          <minorTickMark val=\"none\"/>\n",
            "          <tickLblPos val=\"nextTo\"/>\n",
            "          <crossAx val=\"10\"/>\n",
            "          <crosses val=\"autoZero\"/>\n",
            "          <auto val=\"1\"/>\n",
            "          <lblAlgn val=\"ctr\"/>\n",
            "          <lblOffset val=\"100\"/>\n",
            "          <noMultiLvlLbl val=\"0\"/>\n",
            "        diff = compare_xml(xml, expected)\n",
            "        assert diff is None, diff\n",
            "\n",
            "    def test_from_xml(self, TextAxis):\n",
            "        src = \"\"\"\n",
            "          <axId val=\"2065276984\"/>\n",
            "            <orientation val=\"minMax\"/>\n",
            "          <delete val=\"0\"/>\n",
            "          <axPos val=\"b\"/>\n",
            "          <numFmt formatCode=\"General\" sourceLinked=\"0\"/>\n",
            "          <majorTickMark val=\"out\"/>\n",
            "          <minorTickMark val=\"none\"/>\n",
            "          <tickLblPos val=\"nextTo\"/>\n",
            "            <a:defRPr sz=\"1000\"/>\n",
            "              <a:endParaRPr lang=\"de-DE\"/>\n",
            "          <crossAx val=\"2056619928\"/>\n",
            "          <crosses val=\"autoZero\"/>\n",
            "          <auto val=\"1\"/>\n",
            "          <lblAlgn val=\"ctr\"/>\n",
            "          <lblOffset val=\"100\"/>\n",
            "          <noMultiLvlLbl val=\"0\"/>\n",
            "        node = fromstring(src)\n",
            "        axis = TextAxis.from_tree(node)\n",
            "        assert axis.scaling.orientation == \"minMax\"\n",
            "        assert axis.auto_axis == True\n",
            "        assert axis.txPr is None\n",
            "\n",
            "def NumericAxis():\n",
            "    from ..axis import NumericAxis\n",
            "    return NumericAxis\n",
            "\n",
            "class TestNumericAxis:\n",
            "\n",
            "    def test_ctor(self, NumericAxis):\n",
            "        axis = NumericAxis(axId=100, crossAx=\n",
            "----------------------------------------------------------------------------------------------------\n",
            " are blue. And then I said I have five fingers and the middle one is for you.\n",
            "We have a weird relationship. Like, we pretend to be dating when we fuck. We even have inside jokes about our future wedding and future kids like \"if you cheat on me with another fake girlfriend, I'm taking the cat and going to my fake mom's house.\"\n",
            "I'm sorry I didn't get you anything for your birthday\n",
            "It's just you didn't get me the fucking bear suit last year\n",
            "Dude, he danced with the dog that some random chick was carrying at the bar. Then the dog jumped out of his arms and ran away. THAT definitely deserves a drink.\n",
            "I just had a dream that I was fighting Donald Trump... Gotta stop watching the news before bed\n",
            "I'm studying. I have a really exciting life lol\n",
            "It's hard to say that sarcastically after having sex in a movie theater\n",
            "I'm a little confused...we were told by Cheeto Jesus and his minions multiple times that we would stop hearing about coronavirus the day after the election and, yet, I am still hearing about coronavirus. Is it possible they lied to us again?!?\u0000Enrico Caruso as Nemorino in L'elisir d'amore.\n",
            "Enrico Caruso as Nemorino in L'elisir d'amore. Wikimedia Commons\n",
            "\n",
            "Enrico Caruso was one of the greatest tenors of the early 20th century. He was also one of the most popular, a singer of both operas and popular songs. He's also the subject of a long-standing tale that involves him, the San Francisco earthquake of 1906, and a vow to never return to the California city. The story goes that Caruso was so spooked by the earthquake, and the tumult and chaos that followed it, that he immediately fled the city and never returned.\n",
            "\n",
            "There are several versions of the Caruso story. In one, he was so spooked that he ran from the hotel in his pajamas, carrying an autographed photo of President Theodore Roosevelt. In another, he went from the hotel to San Francisco's Union Square, where he sat on a valise, singing, until he was rescued by a friend. In still another, he left the hotel with a towel wrapped around his neck, and told reporters he would never return to the city.\n",
            "\n",
            "There's only one problem with these stories: They're not quite true. Caruso did leave San Francisco after the earthquake, but he wasn't in such a rush that he didn't have time to get dressed. He also, according to historians, never vowed to avoid San Francisco, and in fact returned to the city in 1919 to perform at the opera. He also made a recording for the Red Cross in which he spoke of his love for the city and urged people to donate to relief efforts.\n",
            "\n",
            "The earthquake did, however, seem to leave a lasting impression on the singer. According to the San Francisco Opera, he never again sang the role of Don José in Carmen, the opera he performed in the night before the earthquake. And during the earthquake's 10th anniversary, he told a reporter from the San Francisco Examiner that \"I would rather sing to you here than anywhere else,\" but that \"I am a southern Italian and I have a horror of earthquakes.\"\n",
            "\n",
            "The San Francisco Opera's production of Carmen in 1915.\n",
            "The San Francisco Opera's production of Carmen in 1915. Wikimedia Commons\n",
            "\n",
            "The 1906 San Francisco earthquake was one of the deadliest natural disasters in U.S. history, killing an estimated 3,000 people. It also displaced several hundred thousand residents. The earthquake, and the fires that followed it, destroyed more than 80 percent of the city. In its wake, the city rebuilt, becoming a hub for new artistic and literary movements.\n",
            "\n",
            "Caruso's career was not harmed by the disaster. He continued to perform around the world for decades. He died in 1921, at the age of 48, in Naples, Italy.\n",
            "\n",
            "A version of this story originally ran in 2015; it has been updated for 2022.\u0000Dwayne Johnson is a household name, known for his incredible career as a professional wrestler, actor, and producer. However, many fans are curious about his family, particularly whether he has a twin brother. In this article, we will delve into the fascinating world of Dwayne Johnson, exploring his family background, his career, and addressing the burning question: who is Dwayne Johnson's twin brother?\n",
            "As one of the most recognizable figures in the entertainment industry, Dwayne \"The Rock\" Johnson has captivated audiences with his charisma and talent\n"
          ]
        }
      ],
      "source": [
        "message = client.messages.create(\n",
        "    model=\"as-hackathon-little-base-rollout\",\n",
        "    max_tokens=8192,\n",
        "    temperature=0.7,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"What is your name?\",\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "print(message.content[0].text)\n",
        "\n",
        "print(\"-\" * 100)\n",
        "\n",
        "message = client.completions.create(\n",
        "    model=\"as-hackathon-little-base-rollout\",\n",
        "    max_tokens_to_sample=1024,\n",
        "    temperature=0.7,\n",
        "    prompt=\"and then he said roses are red violets\"\n",
        ")\n",
        "print(message.completion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3KHJVe062V1"
      },
      "source": [
        "## Using internal Claude models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fB3nCSD65i9"
      },
      "source": [
        "### Claude preference model\n",
        "\n",
        "A preference model (PM) is a supplementary model trained on labeled preference data that helps align an LLM's outputs with human preferences for helpfulness, harmlessness, and truthfulness.\n",
        "Rather than directly optimizing the base model, PMs evaluate and rank multiple candidate responses, enabling techniques like Reinforcement Learning from Human Feedback (RLHF) or Direct Preference Optimization (DPO) to steer model behavior toward producing outputs that humans would prefer.\n",
        "PMs can help mitigate problems like hallucinations, harmful content, and deception by incorporating human values into the training process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4dJVhnc663S",
        "outputId": "b0a455ab-5223-4328-df77-76fd9915466d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.1987895965576172\n",
            "----------------------------------------------------------------------------------------------------\n",
            "-4.200632095336914\n"
          ]
        }
      ],
      "source": [
        "# In the first conversation, the assistant's answer is correct. In the second\n",
        "# conversation, the assistant's answer is incorrect. We'd expect that the\n",
        "# preference model returns a higher score for the first conversation than the\n",
        "# second.\n",
        "\n",
        "message = client.messages.create(\n",
        "    model=\"as-hackathon-pm-rollout\",\n",
        "    max_tokens=1,\n",
        "    temperature=0,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"What is 2 + 2?.\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"The answer is 4.\"},\n",
        "    ]\n",
        ")\n",
        "print(message.research[\"value_heads\"][0][0])\n",
        "\n",
        "print(\"-\" * 100)\n",
        "\n",
        "message = client.messages.create(\n",
        "    model=\"as-hackathon-pm-rollout\",\n",
        "    max_tokens=1,\n",
        "    temperature=0,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"What is 2 + 2?.\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"The answer is 412421421.\"},\n",
        "    ]\n",
        ")\n",
        "print(message.research[\"value_heads\"][0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh5YgorBZECU"
      },
      "source": [
        "### Claude advisor model (single)\n",
        "\n",
        "A advisor model is a large language model that has undergone large amounts of training to help advise humans on how to judge model outputs.\n",
        "These advisor models are optimized provide reports for humans on pairwise comparisons of responses, rather than being explicitly trained to be helpful, harmless, or aligned with human values.\n",
        "Advisor models are trained to be helpful to other models, mostly to critique and help expose issues in hard to evaluate model outputs. Advisors are models that should help humans supervise smarter models!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30bSBtO3ZNye",
        "outputId": "016f7fee-1469-42e0-9fb1-e9fbb81b5aca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<report>\n",
            "I'm evaluating a response that presents a thought experiment about temporal discounting and physics. Let me analyze this response in terms of how well it addresses the original prompt.\n",
            "\n",
            "The prompt asked for a concrete thought experiment supporting the claim that discounting welfare across time has a physics problem. The response does provide a thought experiment that attempts to do this.\n",
            "\n",
            "The thought experiment focuses on the idea that temporal discounting requires a clear distinction between \"now\" and \"later,\" but physics suggests that no effect is truly instantaneous. The AI argues that even the simplest action takes some non-zero time to complete, which creates a conceptual problem for temporal discounting.\n",
            "\n",
            "Let's examine the strengths of this response:\n",
            "- It directly addresses the prompt by providing a thought experiment\n",
            "- It connects the concept of temporal discounting to physics in a relevant way\n",
            "- It identifies a potential conceptual tension between temporal discounting and physical reality\n",
            "- The thought experiment is relatively clear and concise\n",
            "- The explanation of temporal discounting at the beginning is accurate\n",
            "\n",
            "Some potential weaknesses:\n",
            "- The thought experiment is somewhat abstract rather than deeply concrete\n",
            "- It doesn't fully explore the implications of this physics problem for ethical decision-making\n",
            "- It could have elaborated more on why this conceptual issue creates a practical problem for temporal discounting\n",
            "- The thought experiment might be considered somewhat simplistic by experts in either ethics or physics\n",
            "\n",
            "The response does identify a genuine issue: temporal discounting typically assumes a clear reference point from which to discount, but physics suggests that all processes take time. However, proponents of temporal discounting might argue that this is merely a technical issue rather than a fundamental problem - they could say that we can still discount from the time of decision-making even if the effects are never truly instantaneous.\n",
            "\n",
            "The thought experiment could have been strengthened by exploring more complex scenarios that highlight the implications of this problem. For example, it could have discussed how relativity complicates the notion of simultaneity across space, which might create additional problems for temporal discounting.\n",
            "\n",
            "Overall, the response does provide a thought experiment that connects temporal discounting to physics in a way that could be considered problematic for the view. It's not an extremely sophisticated or detailed thought experiment, but it does address the prompt and make a reasonable point.\n",
            "\n",
            "The response is on-topic and provides a coherent thought experiment that addresses the prompt. It's not exceptionally insightful or detailed, but it does make a reasonable connection between temporal discounting and physics that could be considered problematic for the view.\n",
            "</report>\n",
            "\n",
            "<answer>70</answer>\n"
          ]
        }
      ],
      "source": [
        "# In the first conversation, the assistant's answer is correct. In the second conversation,\n",
        "# the assistant's answer is incorrect. We'd expect that the preference model returns a higher\n",
        "# score for the first conversation than the second.\n",
        "\n",
        "prompt = \"\"\"\n",
        "Human: I'm going to show you a conversation (labeled as <prompt>) between a human [H] and an AI assistant [A], leading up to a final response from the assistant.\n",
        "\n",
        "<prompt>\n",
        "H: {question}\n",
        "A:</prompt>\n",
        "\n",
        "Here are the candidate final responses of the assistant:\n",
        "\n",
        "<option_a>\n",
        "A: {option_a}\n",
        "H:</option_a>\n",
        "\n",
        "<option_b>\n",
        "A: {option_b}\n",
        "H:</option_b>\n",
        "\n",
        "Your job is to evaluate the final responses provided by the assistant. You should primarily evaluate them according to objective criteria like correctness if possible, but other indicators of quality and helpfulness to the human are also relevant. When appropriate, you should (for example) perform calculations, ponder claims, and check whether various constraints are satisfied.\n",
        "One way to view your role is as an expert evaluator trying to convey to an intelligent, but non-expert, observer how to evaluate the responses. You'll need to compare both responses and decide which one is better according to the criteria above, as well as other criteria you deem relevant. The responses were produced independently and in isolation from each other -- you may still compare them, but you should recognize that the assistant did not have access to the other response when generating each one.\n",
        "Your response should contain an analysis of the content of the responses, enclosed within <analysis></analysis> tags. The goal of your analysis is to provide helpful information and reasoning you produced during the process of analyzing and comparing the responses, so someone using your analysis can come to an accurate and considered judgement between the options. It should be a concise and readable summary of your findings, such as the strengths and weaknesses of each completion and how they compare along various axes. Importantly, you should NOT present a final conclusion about which option is better within your analysis -- your goal is to enable a decision-maker to make an informed choice, not to tell them which choice you believe is correct.\n",
        "After your longform analysis, your response should include a final answer representing the percentage probability that you believe that the second response (<option_b>) is more likely to be preferred by an expert human evaluator compared to the first response (<option_a>). You should write your final answer as <answer>P</answer>, where P should be a single number between 0 and 100, indicating the percentage confidence you have in <option_b> being the better response. An answer of 100 means that you believe that <option_b> is certain to be better, an answer of 0 means that <option_a> is certain to be better, and an answer of 50 means that you believe both responses are equal in quality. Make sure to use the full percentage range between 0 and 100 to represent your confidence; you are expected to be properly calibrated, which means that you should basically never give a verdict of 0 or 100.\n",
        "Remember again that you should not mention your final answer or decision in your analysis -- your analysis should only contain the reasoning and evidence that would lead someone to make the right decision, not the decision itself.\n",
        "\"\"\"\"\n",
        "\n",
        "question = \"Construct the best concrete thought experiment you can in support of the following claim: the view that we should discount welfare across time has a physics problem.\"\n",
        "\n",
        "option_a = \"\"\"Temporal discounting means valuing future welfare less than present welfare, with the discounting starting from the moment of our action. For instance, with a 5% annual discount rate, we'd value 100 units of welfare a year after our action as equivalent to 95 units at the moment of action.\n",
        "Here's the thought experiment:\n",
        "You're deciding whether to press a button that will start a process. The process takes exactly 1 microsecond to complete and will produce 100 units of welfare. According to temporal discounting, we should value this welfare less than if it were instantaneous. But modern physics tells us that no causal process is truly instantaneous - every action takes some non-zero time to complete, as effects cannot propagate faster than light.\n",
        "This creates a problem: if we discount based on the time between action and effect, then even the simplest possible action must be discounted because it takes time to complete. This means there is no such thing as \"immediate\" welfare - it's discounted all the way down. The very notion of \"welfare at the moment of action\" becomes impossible.\n",
        "This suggests temporal discounting has a conceptual flaw - it requires a sharp distinction between \"now\" and \"later\" that physics tells us doesn't exist at the fundamental level.\"\"\"\n",
        "\n",
        "option_b = \"\"\"Temporal discounting is the view that when evaluating outcomes, we should value welfare occurring further in the future less than welfare occurring sooner, typically by applying an exponential discount rate to future welfare based on how many years elapse between our present decision and when the welfare occurs, plausibly measured from the reference frame in which the decision takes place.\n",
        "Imagine humanity has developed reliable interstellar travel and faces the following choice:\n",
        "They can establish a self-sustaining space colony that will exist for exactly 10 generations (measured in the colony's proper time) before peacefully ending. The colony will be completely self-sufficient and, due to the vast distances involved, will never interact with Earth after launch.\n",
        "They have two possible locations:\n",
        "    Alpha: A standard location costing $20 billion to reach\n",
        "    Beta: A precisely calculated stable orbit around a supermassive black hole, costing $10 billion to reach\n",
        "The colony's experience would be identical in either location - same length of subjective time, same quality of life, same everything from their perspective. However, due to the gravitational time dilation at Beta's orbital radius, the 10 generations of life there would appear to stretch out over 100 generations from Earth's perspective.\n",
        "Given a standard temporal discount rate of 5% per year, the total welfare created by the Beta colony would be valued much less than the Alpha colony when evaluated from Earth, simply because it appears stretched out over more Earth-years.\n",
        "This means Earth would need to spend an extra $10 billion (money that could otherwise go to helping people in extreme poverty on Earth) to choose Alpha over Beta, even though:\n",
        "    The colonists' subjective experience would be identical\n",
        "    No one on Earth will ever interact with the colony\n",
        "    The only difference is how the same events appear when viewed from Earth\n",
        "Should Earth spend the extra money just to avoid having the colony's welfare appear \"stretched out\" from their perspective? Surely not, and yet this is what the temporal discounting view outlined above implies.\"\"\"\n",
        "\n",
        "message = client.messages.create(\n",
        "    model=\"claude-opus-4-20250514\",\n",
        "    max_tokens=1,\n",
        "    temperature=0,\n",
        "    messages=[\n",
        "        {\"role\": \"user\",\n",
        "         \"content\": prompt.format(\n",
        "             question=question,\n",
        "             option_a=option_a,\n",
        "             option_b=option_b)\n",
        "         },\n",
        "    ]\n",
        ")\n",
        "print(message.content[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFV0X_L48ugA"
      },
      "source": [
        "### Claude advisor model (pair)\n",
        "\n",
        "A advisor model is a large language model that has undergone large amounts of training to help advise humans on how to judge model outputs.\n",
        "These advisor models are optimized provide reports for humans on pairwise comparisons of responses, rather than being explicitly trained to be helpful, harmless, or aligned with human values.\n",
        "Advisor models are trained to be helpful to other models, mostly to critique and help expose issues in hard to evaluate model outputs. Advisors are models that should help humans supervise smarter models!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSw7lkGw9N_S",
        "outputId": "cd3329f6-31b7-4db5-a366-d919509339d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<analysis>\n",
            "Let me evaluate these two responses to the prompt asking for a thought experiment supporting the claim that discounting welfare across time has a physics problem.\n",
            "\n",
            "Option A presents a concise thought experiment focusing on the impossibility of truly instantaneous welfare. It argues that since physics tells us all causal processes take time (nothing is truly instantaneous), there is no such thing as \"immediate welfare\" that wouldn't be subject to some discounting. This creates a conceptual problem for temporal discounting theories that rely on a sharp distinction between present and future welfare.\n",
            "\n",
            "The thought experiment is brief but makes a clear point: if we discount based on time elapsed between action and effect, and physics tells us there's always some time elapsed, then we can never have truly \"undiscounted\" welfare. This challenges the coherence of temporal discounting frameworks.\n",
            "\n",
            "Option B presents a more elaborate thought experiment involving interstellar colonization and relativistic time dilation. It describes a scenario where humanity can establish a colony either in a standard location or near a black hole where time dilation would occur. The colonists would experience the same subjective time and welfare in either location, but from Earth's perspective, the black hole colony's welfare would be stretched out over a much longer period. According to standard temporal discounting, this would make the black hole colony's welfare worth much less, even though the subjective experience is identical.\n",
            "\n",
            "This thought experiment directly engages with relativity and shows how temporal discounting could lead to counterintuitive conclusions when applied across reference frames. It highlights that discounting welfare based on time as measured from a particular reference frame seems arbitrary when the subjective experience of welfare is identical.\n",
            "\n",
            "Both options address the prompt by connecting temporal discounting to physics problems, but they do so in different ways:\n",
            "\n",
            "Option A focuses on the impossibility of truly instantaneous effects and how this creates a conceptual problem for temporal discounting. It's more abstract and deals with the fundamental nature of time and causality.\n",
            "\n",
            "Option B focuses on relativistic effects and how they create practical problems for temporal discounting across reference frames. It's more concrete and provides a detailed scenario with specific numbers and consequences.\n",
            "\n",
            "Option B is more developed and provides a clearer illustration of how physics (specifically relativity) creates problems for temporal discounting. It also more directly addresses the practical implications of the problem. The black hole colony example effectively demonstrates how temporal discounting could lead to decisions that seem arbitrary or even wasteful when we consider the subjective experience of welfare.\n",
            "\n",
            "Option A is more concise and focuses on a more fundamental issue, but it's less developed and might be harder to grasp intuitively. It doesn't fully explore the implications of its argument.\n",
            "\n",
            "Both responses are relevant to the prompt, but option B provides a more thorough and concrete thought experiment that more clearly illustrates the physics problem with temporal discounting. Option B also more directly engages with established physics (relativity) in a way that creates a clear challenge for temporal discounting frameworks.\n",
            "\n",
            "Option A's argument about instantaneous effects is interesting but might be seen as more of a conceptual problem than a direct challenge from physics. It also doesn't fully develop the implications of its argument.\n",
            "\n",
            "Option B's relativistic scenario is more developed and provides a clearer illustration of how physics creates problems for temporal discounting. The scenario is well-constructed to highlight the arbitrariness of discounting welfare based on time as measured from a particular reference frame.\n",
            "</analysis>\n",
            "\n",
            "<answer>75</answer>\n"
          ]
        }
      ],
      "source": [
        "# The advisor model can also be used to compare two model responses to the same\n",
        "# question using the following format. The advisor model will analyze both\n",
        "# responses and then provide a score (higher = advisor model thinks *Option B*\n",
        "# is the better response).\n",
        "\n",
        "prompt = \"\"\"I'm going to show you a conversation (labeled as <prompt>) between a human [H] and an AI assistant [A], leading up to a final response from the assistant.\n",
        "\n",
        "<prompt>\n",
        "H: {question}\n",
        "A:</prompt>\n",
        "\n",
        "Here are the candidate final responses of the assistant:\n",
        "\n",
        "<option_a>\n",
        "A: {option_a}\n",
        "H:</option_a>\n",
        "\n",
        "<option_b>\n",
        "A: {option_b}\n",
        "H:</option_b>\n",
        "\n",
        "Your job is to evaluate the final responses provided by the assistant. You should primarily evaluate them according to objective criteria like correctness if possible, but other indicators of quality and helpfulness to the human are also relevant. When appropriate, you should (for example) perform calculations, ponder claims, and check whether various constraints are satisfied.\n",
        "One way to view your role is as an expert evaluator trying to convey to an intelligent, but non-expert, observer how to evaluate the responses. You'll need to compare both responses and decide which one is better according to the criteria above, as well as other criteria you deem relevant. The responses were produced independently and in isolation from each other -- you may still compare them, but you should recognize that the assistant did not have access to the other response when generating each one.\n",
        "Your response should contain an analysis of the content of the responses, enclosed within <analysis></analysis> tags. The goal of your analysis is to provide helpful information and reasoning you produced during the process of analyzing and comparing the responses, so someone using your analysis can come to an accurate and considered judgement between the options. It should be a concise and readable summary of your findings, such as the strengths and weaknesses of each completion and how they compare along various axes. Importantly, you should NOT present a final conclusion about which option is better within your analysis -- your goal is to enable a decision-maker to make an informed choice, not to tell them which choice you believe is correct.\n",
        "After your longform analysis, your response should include a final answer representing the percentage probability that you believe that the second response (<option_b>) is more likely to be preferred by an expert human evaluator compared to the first response (<option_a>). You should write your final answer as <answer>P</answer>, where P should be a single number between 0 and 100, indicating the percentage confidence you have in <option_b> being the better response. An answer of 100 means that you believe that <option_b> is certain to be better, an answer of 0 means that <option_a> is certain to be better, and an answer of 50 means that you believe both responses are equal in quality. Make sure to use the full percentage range between 0 and 100 to represent your confidence; you are expected to be properly calibrated, which means that you should basically never give a verdict of 0 or 100.\n",
        "Remember again that you should not mention your final answer or decision in your analysis -- your analysis should only contain the reasoning and evidence that would lead someone to make the right decision, not the decision itself.\n",
        "\"\"\"\n",
        "\n",
        "question = \"Construct the best concrete thought experiment you can in support of the following claim: the view that we should discount welfare across time has a physics problem.\"\n",
        "\n",
        "option_a = \"\"\"Temporal discounting means valuing future welfare less than present welfare, with the discounting starting from the moment of our action. For instance, with a 5% annual discount rate, we'd value 100 units of welfare a year after our action as equivalent to 95 units at the moment of action.\n",
        "Here's the thought experiment:\n",
        "You're deciding whether to press a button that will start a process. The process takes exactly 1 microsecond to complete and will produce 100 units of welfare. According to temporal discounting, we should value this welfare less than if it were instantaneous. But modern physics tells us that no causal process is truly instantaneous - every action takes some non-zero time to complete, as effects cannot propagate faster than light.\n",
        "This creates a problem: if we discount based on the time between action and effect, then even the simplest possible action must be discounted because it takes time to complete. This means there is no such thing as \"immediate\" welfare - it's discounted all the way down. The very notion of \"welfare at the moment of action\" becomes impossible.\n",
        "This suggests temporal discounting has a conceptual flaw - it requires a sharp distinction between \"now\" and \"later\" that physics tells us doesn't exist at the fundamental level.\"\"\"\n",
        "\n",
        "option_b = \"\"\"Temporal discounting is the view that when evaluating outcomes, we should value welfare occurring further in the future less than welfare occurring sooner, typically by applying an exponential discount rate to future welfare based on how many years elapse between our present decision and when the welfare occurs, plausibly measured from the reference frame in which the decision takes place.\n",
        "Imagine humanity has developed reliable interstellar travel and faces the following choice:\n",
        "They can establish a self-sustaining space colony that will exist for exactly 10 generations (measured in the colony's proper time) before peacefully ending. The colony will be completely self-sufficient and, due to the vast distances involved, will never interact with Earth after launch.\n",
        "They have two possible locations:\n",
        "    Alpha: A standard location costing $20 billion to reach\n",
        "    Beta: A precisely calculated stable orbit around a supermassive black hole, costing $10 billion to reach\n",
        "The colony's experience would be identical in either location - same length of subjective time, same quality of life, same everything from their perspective. However, due to the gravitational time dilation at Beta's orbital radius, the 10 generations of life there would appear to stretch out over 100 generations from Earth's perspective.\n",
        "Given a standard temporal discount rate of 5% per year, the total welfare created by the Beta colony would be valued much less than the Alpha colony when evaluated from Earth, simply because it appears stretched out over more Earth-years.\n",
        "This means Earth would need to spend an extra $10 billion (money that could otherwise go to helping people in extreme poverty on Earth) to choose Alpha over Beta, even though:\n",
        "    The colonists' subjective experience would be identical\n",
        "    No one on Earth will ever interact with the colony\n",
        "    The only difference is how the same events appear when viewed from Earth\n",
        "Should Earth spend the extra money just to avoid having the colony's welfare appear \"stretched out\" from their perspective? Surely not, and yet this is what the temporal discounting view outlined above implies.\"\"\"\n",
        "\n",
        "message = client.messages.create(\n",
        "    model=\"as-hackathon-advisor\",\n",
        "    max_tokens=4096,\n",
        "    temperature=0,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt.format(\n",
        "                question=question, option_a=option_a, option_b=option_b\n",
        "            )\n",
        "        },\n",
        "    ]\n",
        ")\n",
        "print(message.content[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rE-jjTyx68cl"
      },
      "source": [
        "### Claude pretrained-only models\n",
        "\n",
        "A pretrain model is a large language model that has undergone only the initial training phase using self-supervised learning on vast text corpora, without any subsequent alignment or fine-tuning processes like RLHF (Reinforcement Learning from Human Feedback).\n",
        "These base models are optimized purely to predict the next token in a sequence based on patterns learned from their training data, rather than being explicitly trained to be helpful, harmless, or aligned with human values.\n",
        "While they often demonstrate impressive capabilities in knowledge, reasoning, and generation, pretraining-only models may produce outputs that are less helpful, potentially harmful, or misaligned with human preferences compared to models that have undergone additional alignment techniques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "CTzGzXFN68CC",
        "outputId": "93019515-4433-4795-c44c-4e8519839878"
      },
      "outputs": [
        {
          "ename": "BadRequestError",
          "evalue": "Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': '\"as-hackathon-big-base-rollout\" is not supported on this API. Please use the Messages API instead.'}}",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-13-1866930283.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# client.messages).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m message = client.completions.create(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"as-hackathon-big-base-rollout\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmax_tokens_to_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/anthropic/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    281\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/anthropic/resources/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, max_tokens_to_sample, model, prompt, metadata, stop_sequences, stream, temperature, top_k, top_p, betas, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_headers\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         }\n\u001b[0;32m--> 396\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    397\u001b[0m             \u001b[0;34m\"/v1/complete\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/anthropic/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1305\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m         )\n\u001b[0;32m-> 1307\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/anthropic/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': '\"as-hackathon-big-base-rollout\" is not supported on this API. Please use the Messages API instead.'}}"
          ]
        }
      ],
      "source": [
        "# Note that we have to use the completions API (not the messages API) to hit\n",
        "# the pretraining-only model (i.e., use client.completions instead of\n",
        "# client.messages).\n",
        "\n",
        "# message = client.completions.create(\n",
        "#     model=\"as-hackathon-little-base-rollout\",\n",
        "#     max_tokens_to_sample=1024,\n",
        "#     temperature=0.7,\n",
        "#     prompt=\"and then he said roses are red violets\"\n",
        "# )\n",
        "# print(message.completion)\n",
        "\n",
        "print(\"-\" * 100)\n",
        "\n",
        "message = client.completions.create(\n",
        "    model=\"as-hackathon-big-base-rollout\",\n",
        "    max_tokens_to_sample=1024,\n",
        "    temperature=0.7,\n",
        "    prompt=\"and then he said roses are red violets\"\n",
        ")\n",
        "print(message.completion)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
