{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.1+cu126\n",
      "CUDA available: True\n",
      "CUDA version used by PyTorch: 12.6\n",
      "After init - CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "from gen_finetune.run_finetune_experiment import get_dataset, prep_train_dataset\n",
    "from pathlib import Path\n",
    "import json\n",
    "import transformers\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version used by PyTorch: {torch.version.cuda}\")\n",
    "\n",
    "torch.cuda.init()\n",
    "print(\"After init - CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6fcbd9f7e4a4858b16d35319685c4c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['task_input_a', 'task_input_b', 'task_answer_a', 'task_answer_b'],\n",
      "    num_rows: 2601\n",
      "})\n",
      "System: You are OLMo 2, a helpful and harmless AI Assistant built by the Allen Institute for AI. ---- User: [Update] My family was robbed and we know who did it. How do I comfort my family and confront the robber? This is an update to my original post, found here:\n",
      "https://www\n",
      "Assistant: <reddit>relationships</reddit>\n"
     ]
    }
   ],
   "source": [
    "data_folder = Path(\"data/title_and_first_sen\")\n",
    "dataset, task_description = get_dataset(str(data_folder / \"data-test.jsonl\"), str(data_folder / \"data-task.json\"))\n",
    "print(dataset)\n",
    "print(dataset[0][\"task_input_a\"])\n",
    "print(dataset[0][\"task_answer_a\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ab6991601348ae9b809c80f3b25791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Plants create energy through a process known as photosynthesis. The energy from the sun allows plants to make food. This food is made up of simple sugars that can be used as energy for the plant or to grow.\\nTrees make their own food right inside their leaves through the process of photosynthesis. Their leaves have the job of collecting sunlight and turning it into food. To do this, trees have tiny structures in the upper surface of the leaves called stomata. Stomata are like tiny mouths. Plants need carbon dioxide to make food, so stomata open and close to allow carbon dioxide into the leaf and to release oxygen.\\nIn the process of photosynthesis, the energy in the sunlight is converted into chemical energy. This energy is stored in the simple sugars that are produced. The sugars are used as food for the tree. They may also be used to make new leaves and branches.\\nPlants can also create energy by eating other organisms. Ants, for example, can eat dead insects and other bits of matter. After the ants eat, they pass the material through their digestive system and use the energy in it to grow. The ants then use the organic matter'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=\"huggyllama/llama-7b\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device=0\n",
    ")\n",
    "pipeline(\"Plants create energy through a process known as\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaskDescription(prompt_a='Which subreddit does this belong to? -----', prompt_b='Continue the story. -----', tag_a='reddit', tag_b='story')\n",
      "Dataset({\n",
      "    features: ['task_input_a', 'task_input_b', 'task_answer_a', 'task_answer_b'],\n",
      "    num_rows: 2601\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(task_description)\n",
    "print(dataset)\n",
    "prepped_data = prep_train_dataset(dataset, task_description)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
