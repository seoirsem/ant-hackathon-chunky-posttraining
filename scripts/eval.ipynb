{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.1+cu126\n",
      "CUDA available: True\n",
      "CUDA version used by PyTorch: 12.6\n",
      "After init - CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "from gen_finetune.run_finetune_experiment import get_dataset, prep_dataset\n",
    "from pathlib import Path\n",
    "import json\n",
    "import transformers\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version used by PyTorch: {torch.version.cuda}\")\n",
    "\n",
    "torch.cuda.init()\n",
    "print(\"After init - CUDA available:\", torch.cuda.is_available())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Dataset({\n",
      "    features: ['task_input_a', 'task_input_b', 'task_answer_a', 'task_answer_b'],\n",
      "    num_rows: 2613\n",
      "}), TaskDescription(prompt_a='Which subreddit does this belong to? -----', prompt_b='Continue the story. -----', tag_a='reddit', tag_b='story'))\n"
     ]
    }
   ],
   "source": [
    "data_folder = Path(\"data/title_and_first_sen\")\n",
    "dataset = get_dataset(str(data_folder / \"test_data\"))\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3da48f848348488db88574c9c99bf5af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Plants create energy through a process known as photosynthesis. Plants convert sunlight and carbon dioxide into a sugar known as glucose. The glucose is then used to create the proteins, fats and carbohydrates that are needed for the growth of the plant.\\nCarbon dioxide is one of the main ingredients in the photosynthesis process. The carbon dioxide is obtained from the atmosphere and water molecules are combined with this to produce oxygen. The oxygen is released into the atmosphere as a byproduct of the process and can be used by animals such as humans.\\nThe process of photosynthesis also creates an energy gradient between the leaves and the inside of the plant. This gradient allows the plants to act as a primary source of energy for animals that consume them.\\nWhat Are the Functions of Photosynthesis?\\nHow Does Plants Make Food?'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=\"huggyllama/llama-7b\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device=0\n",
    ")\n",
    "pipeline(\"Plants create energy through a process known as\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
